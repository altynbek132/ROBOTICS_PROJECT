{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b7c308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import finish\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "print('import finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb940f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_number = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4828415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048637, 37)\n",
      "(12719, 37)\n",
      "(4115, 37)\n",
      "(281, 37)\n",
      "(134, 37)\n",
      "(890, 37)\n",
      "(27205, 37)\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for file_name in list(os.listdir('datasets')):\n",
    "    dataset = np.loadtxt(f'datasets/{file_name}')\n",
    "    datasets.append(dataset)\n",
    "    print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "947e27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5   1.    0.5 ]\n",
      " [ 0.25  0.5   0.75]\n",
      " [-4.   -5.   -6.  ]]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # test\n",
    "    vels = np.array([\n",
    "        [1,2,3],\n",
    "        [4,4,4],\n",
    "        [5,6,7],\n",
    "        [1,1,1]\n",
    "    ])\n",
    "    diff_v = (np.diff(vels, axis=0))\n",
    "    diff_t = np.array([\n",
    "        2,\n",
    "        4,\n",
    "        1\n",
    "    ])\n",
    "    acc = np.transpose(np.transpose(diff_v)/diff_t)\n",
    "    print(acc)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a3e1090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 37)\n",
      "(2, 12)\n",
      "[[  0   1   2 123   3   4   5 123   6   7   8 123   9  10  11 123  12  13\n",
      "   14 123  15  16  17 123  18  19  20 123  21  22  23 123  24  25  26 123\n",
      "   27  28  29 123  30  31  32 123  33  34  35 123  36]\n",
      " [  0   1   2 123   3   4   5 123   6   7   8 123   9  10  11 123  12  13\n",
      "   14 123  15  16  17 123  18  19  20 123  21  22  23 123  24  25  26 123\n",
      "   27  28  29 123  30  31  32 123  33  34  35 123  36]]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "#     test insert acc to to table\n",
    "    table = np.array([\n",
    "        list(range(37)),\n",
    "        list(range(37)),\n",
    "    ])\n",
    "    acc = np.array(\n",
    "    [\n",
    "        [123 for i in range(12)],\n",
    "        [123 for i in range(12)],\n",
    "    ]\n",
    "    )\n",
    "    print(table.shape)\n",
    "    print(acc.shape)\n",
    "    full = np.insert(table, list(range(3, 3 * joint_number + 1, 3)), acc, axis=1)\n",
    "    print(full)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a6b5f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1093974, 48)\n"
     ]
    }
   ],
   "source": [
    "full_datasets = []\n",
    "for dataset in datasets:\n",
    "#     print(dataset.shape)\n",
    "    time = dataset[:, 0]\n",
    "    velocities = dataset[:, 2::3]\n",
    "    diff_v = np.diff(velocities, axis=0)\n",
    "    diff_t = np.diff(time, axis=0)\n",
    "    acc = np.transpose(np.transpose(diff_v)/diff_t)\n",
    "    full_dataset = np.insert(dataset[0:-1], list(range(3, 3 * joint_number + 1, 3)), acc, axis=1)\n",
    "    # remote time column\n",
    "    full_dataset = full_dataset[:, 1:]\n",
    "    full_datasets.append(full_dataset)\n",
    "#     print(full_dataset.shape)\n",
    "\n",
    "full_dataset = np.concatenate(full_datasets)\n",
    "print(full_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3592e79b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3 999   5   6   7 999]\n",
      " [  0   1   2   3 999   5   6   7 999]]\n",
      "(2, 9)\n",
      "[[1 2 3 5 6 7]\n",
      " [1 2 3 5 6 7]]\n",
      "(2, 6)\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # remove torques\n",
    "    exampleInput = [\n",
    "    #    time, pos, vel, acc, torque, pos2, vel2, acc2, torque2, ...\n",
    "        [0,    1,   2,   3,   999,      5,    6,    7,    999],\n",
    "        [0,    1,   2,   3,   999,      5,    6,    7,    999],\n",
    "    ]\n",
    "    exampleInput = np.array(exampleInput)\n",
    "    print(exampleInput)\n",
    "    print(exampleInput.shape)\n",
    "\n",
    "    trainX = np.delete(exampleInput, slice(0, None, 4), 1)\n",
    "    print(trainX)\n",
    "    print(trainX.shape)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e53d840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "(3, 3)\n",
      "[[0.         0.14285714 0.25      ]\n",
      " [0.5        0.57142857 0.625     ]\n",
      " [1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # interpolate ex\n",
    "    arr = np.arange(9).reshape(3, 3)\n",
    "    print(arr)\n",
    "    maxes = np.max(arr, axis=0)\n",
    "    print(arr.shape)\n",
    "    print(arr/maxes)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "527a18f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1093974, 48)\n",
      "(1093974, 48)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# interpolate\n",
    "maxes = np.max(full_dataset, axis=0)\n",
    "print(full_dataset.shape)\n",
    "table_interpolated = full_dataset/maxes\n",
    "print(table_interpolated.shape)\n",
    "# should be 1.0\n",
    "print(np.max(table_interpolated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "854ac537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1039275, 48)\n",
      "(54699, 48)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(table_interpolated)\n",
    "train = table_interpolated[0:int(table_interpolated.shape[0] * 0.95)]\n",
    "test = table_interpolated[int(table_interpolated.shape[0] * 0.95):]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(np.max(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d44e33b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_to_x_y(table):\n",
    "    X = np.delete(table, slice(0, None, 4), 1)\n",
    "    Y = table[:, 2::4]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4a4ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = split_to_x_y(train), split_to_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3eab4d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(range(trainY[:, 0].shape[0])), trainY[:, 0], marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bfb7417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1039275, 36)\n",
      "(1039275, 12)\n",
      "(54699, 36)\n",
      "(54699, 12)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e88c071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=((joint_number * 3), )))\n",
    "# hidden\n",
    "model.add(Dense(joint_number * 3, activation=\"relu\"))\n",
    "model.add(Dense(joint_number * 3, activation=\"relu\"))\n",
    "model.add(Dense(joint_number * 3, activation=\"relu\"))\n",
    "# output layer\n",
    "model.add(Dense(joint_number, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "321547f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for best_saved_model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filepath_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_best\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for best_saved_model"
     ]
    }
   ],
   "source": [
    "filepath_best = 'best_saved_model'\n",
    "model.load_weights(filepath_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6d3c2897",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'saved_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filepath_backup \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_weights/saved-model-epoch-\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-mse-\u001b[39m\u001b[38;5;132;01m{mse:.2f}\u001b[39;00m\u001b[38;5;124m-mae-\u001b[39m\u001b[38;5;132;01m{mae:.2f}\u001b[39;00m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved_weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'saved_weights'"
     ]
    }
   ],
   "source": [
    "filepath_backup = \"saved_weights/saved-model-epoch-{epoch:02d}-mse-{mse:.2f}-mae-{mae:.2f}.hdf5\"\n",
    "os.mkdir('saved_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2577507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_all = keras.callbacks.ModelCheckpoint(filepath_backup, monitor='mse', verbose=1, save_weights_only=True,\n",
    ")\n",
    "checkpoint_best = keras.callbacks.ModelCheckpoint(filepath_best, monitor='mse', verbose=1, save_best_only=True, mode='min',save_weights_only=True,\n",
    ")\n",
    "checkpoint_best_full = keras.callbacks.ModelCheckpoint(filepath_best, monitor='mse', verbose=1, save_best_only=True, mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e7104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/1000\n",
      "32427/32478 [============================>.] - ETA: 0s - loss: 0.0354 - mse: 0.0354 - mae: 0.1362\n",
      "Epoch 1: saving model to saved_weights/saved-model-epoch-01-mse-0.04-mae-0.14.hdf5\n",
      "\n",
      "Epoch 1: mse improved from inf to 0.03540, saving model to best_saved_model\n",
      "\n",
      "Epoch 1: mse improved from inf to 0.03540, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 627us/step - loss: 0.0354 - mse: 0.0354 - mae: 0.1362 - val_loss: 0.0350 - val_mse: 0.0350 - val_mae: 0.1356\n",
      "Epoch 2/1000\n",
      "32432/32478 [============================>.] - ETA: 0s - loss: 0.0338 - mse: 0.0338 - mae: 0.1339\n",
      "Epoch 2: saving model to saved_weights/saved-model-epoch-02-mse-0.03-mae-0.13.hdf5\n",
      "\n",
      "Epoch 2: mse improved from 0.03540 to 0.03384, saving model to best_saved_model\n",
      "\n",
      "Epoch 2: mse improved from 0.03540 to 0.03384, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 28s 868us/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1339 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1317\n",
      "Epoch 3/1000\n",
      "32425/32478 [============================>.] - ETA: 0s - loss: 0.0304 - mse: 0.0304 - mae: 0.1283\n",
      "Epoch 3: saving model to saved_weights/saved-model-epoch-03-mse-0.03-mae-0.13.hdf5\n",
      "\n",
      "Epoch 3: mse improved from 0.03384 to 0.03036, saving model to best_saved_model\n",
      "\n",
      "Epoch 3: mse improved from 0.03384 to 0.03036, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 29s 889us/step - loss: 0.0304 - mse: 0.0304 - mae: 0.1283 - val_loss: 0.0287 - val_mse: 0.0287 - val_mae: 0.1254\n",
      "Epoch 4/1000\n",
      "32453/32478 [============================>.] - ETA: 0s - loss: 0.0278 - mse: 0.0278 - mae: 0.1238\n",
      "Epoch 4: saving model to saved_weights/saved-model-epoch-04-mse-0.03-mae-0.12.hdf5\n",
      "\n",
      "Epoch 4: mse improved from 0.03036 to 0.02782, saving model to best_saved_model\n",
      "\n",
      "Epoch 4: mse improved from 0.03036 to 0.02782, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 738us/step - loss: 0.0278 - mse: 0.0278 - mae: 0.1238 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1229\n",
      "Epoch 5/1000\n",
      "32433/32478 [============================>.] - ETA: 0s - loss: 0.0269 - mse: 0.0269 - mae: 0.1222\n",
      "Epoch 5: saving model to saved_weights/saved-model-epoch-05-mse-0.03-mae-0.12.hdf5\n",
      "\n",
      "Epoch 5: mse improved from 0.02782 to 0.02689, saving model to best_saved_model\n",
      "\n",
      "Epoch 5: mse improved from 0.02782 to 0.02689, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 807us/step - loss: 0.0269 - mse: 0.0269 - mae: 0.1222 - val_loss: 0.0267 - val_mse: 0.0267 - val_mae: 0.1218\n",
      "Epoch 6/1000\n",
      "32404/32478 [============================>.] - ETA: 0s - loss: 0.0264 - mse: 0.0264 - mae: 0.1212\n",
      "Epoch 6: saving model to saved_weights/saved-model-epoch-06-mse-0.03-mae-0.12.hdf5\n",
      "\n",
      "Epoch 6: mse improved from 0.02689 to 0.02637, saving model to best_saved_model\n",
      "\n",
      "Epoch 6: mse improved from 0.02689 to 0.02637, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 667us/step - loss: 0.0264 - mse: 0.0264 - mae: 0.1212 - val_loss: 0.0262 - val_mse: 0.0262 - val_mae: 0.1209\n",
      "Epoch 7/1000\n",
      "32445/32478 [============================>.] - ETA: 0s - loss: 0.0259 - mse: 0.0259 - mae: 0.1202\n",
      "Epoch 7: saving model to saved_weights/saved-model-epoch-07-mse-0.03-mae-0.12.hdf5\n",
      "\n",
      "Epoch 7: mse improved from 0.02637 to 0.02589, saving model to best_saved_model\n",
      "\n",
      "Epoch 7: mse improved from 0.02637 to 0.02589, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 28s 849us/step - loss: 0.0259 - mse: 0.0259 - mae: 0.1202 - val_loss: 0.0257 - val_mse: 0.0257 - val_mae: 0.1199\n",
      "Epoch 8/1000\n",
      "32435/32478 [============================>.] - ETA: 0s - loss: 0.0254 - mse: 0.0254 - mae: 0.1193\n",
      "Epoch 8: saving model to saved_weights/saved-model-epoch-08-mse-0.03-mae-0.12.hdf5\n",
      "\n",
      "Epoch 8: mse improved from 0.02589 to 0.02540, saving model to best_saved_model\n",
      "\n",
      "Epoch 8: mse improved from 0.02589 to 0.02540, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 40s 1ms/step - loss: 0.0254 - mse: 0.0254 - mae: 0.1193 - val_loss: 0.0253 - val_mse: 0.0253 - val_mae: 0.1190\n",
      "Epoch 9/1000\n",
      "32448/32478 [============================>.] - ETA: 0s - loss: 0.0250 - mse: 0.0250 - mae: 0.1184\n",
      "Epoch 9: saving model to saved_weights/saved-model-epoch-09-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 9: mse improved from 0.02540 to 0.02499, saving model to best_saved_model\n",
      "\n",
      "Epoch 9: mse improved from 0.02540 to 0.02499, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 784us/step - loss: 0.0250 - mse: 0.0250 - mae: 0.1184 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1182\n",
      "Epoch 10/1000\n",
      "32466/32478 [============================>.] - ETA: 0s - loss: 0.0247 - mse: 0.0247 - mae: 0.1177\n",
      "Epoch 10: saving model to saved_weights/saved-model-epoch-10-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 10: mse improved from 0.02499 to 0.02467, saving model to best_saved_model\n",
      "\n",
      "Epoch 10: mse improved from 0.02499 to 0.02467, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 693us/step - loss: 0.0247 - mse: 0.0247 - mae: 0.1177 - val_loss: 0.0246 - val_mse: 0.0246 - val_mae: 0.1176\n",
      "Epoch 11/1000\n",
      "32461/32478 [============================>.] - ETA: 0s - loss: 0.0244 - mse: 0.0244 - mae: 0.1172\n",
      "Epoch 11: saving model to saved_weights/saved-model-epoch-11-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 11: mse improved from 0.02467 to 0.02444, saving model to best_saved_model\n",
      "\n",
      "Epoch 11: mse improved from 0.02467 to 0.02444, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 692us/step - loss: 0.0244 - mse: 0.0244 - mae: 0.1172 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1171\n",
      "Epoch 12/1000\n",
      "32446/32478 [============================>.] - ETA: 0s - loss: 0.0243 - mse: 0.0243 - mae: 0.1168\n",
      "Epoch 12: saving model to saved_weights/saved-model-epoch-12-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 12: mse improved from 0.02444 to 0.02427, saving model to best_saved_model\n",
      "\n",
      "Epoch 12: mse improved from 0.02444 to 0.02427, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 699us/step - loss: 0.0243 - mse: 0.0243 - mae: 0.1168 - val_loss: 0.0243 - val_mse: 0.0243 - val_mae: 0.1167\n",
      "Epoch 13/1000\n",
      "32457/32478 [============================>.] - ETA: 0s - loss: 0.0241 - mse: 0.0241 - mae: 0.1164\n",
      "Epoch 13: saving model to saved_weights/saved-model-epoch-13-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 13: mse improved from 0.02427 to 0.02414, saving model to best_saved_model\n",
      "\n",
      "Epoch 13: mse improved from 0.02427 to 0.02414, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 647us/step - loss: 0.0241 - mse: 0.0241 - mae: 0.1164 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1164\n",
      "Epoch 14/1000\n",
      "32423/32478 [============================>.] - ETA: 0s - loss: 0.0240 - mse: 0.0240 - mae: 0.1161\n",
      "Epoch 14: saving model to saved_weights/saved-model-epoch-14-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 14: mse improved from 0.02414 to 0.02403, saving model to best_saved_model\n",
      "\n",
      "Epoch 14: mse improved from 0.02414 to 0.02403, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 637us/step - loss: 0.0240 - mse: 0.0240 - mae: 0.1161 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1161\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32394/32478 [============================>.] - ETA: 0s - loss: 0.0239 - mse: 0.0239 - mae: 0.1158\n",
      "Epoch 15: saving model to saved_weights/saved-model-epoch-15-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 15: mse improved from 0.02403 to 0.02394, saving model to best_saved_model\n",
      "\n",
      "Epoch 15: mse improved from 0.02403 to 0.02394, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 645us/step - loss: 0.0239 - mse: 0.0239 - mae: 0.1158 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1159\n",
      "Epoch 16/1000\n",
      "32448/32478 [============================>.] - ETA: 0s - loss: 0.0239 - mse: 0.0239 - mae: 0.1156\n",
      "Epoch 16: saving model to saved_weights/saved-model-epoch-16-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 16: mse improved from 0.02394 to 0.02386, saving model to best_saved_model\n",
      "\n",
      "Epoch 16: mse improved from 0.02394 to 0.02386, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 606us/step - loss: 0.0239 - mse: 0.0239 - mae: 0.1156 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1157\n",
      "Epoch 17/1000\n",
      "32476/32478 [============================>.] - ETA: 0s - loss: 0.0238 - mse: 0.0238 - mae: 0.1154\n",
      "Epoch 17: saving model to saved_weights/saved-model-epoch-17-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 17: mse improved from 0.02386 to 0.02378, saving model to best_saved_model\n",
      "\n",
      "Epoch 17: mse improved from 0.02386 to 0.02378, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 628us/step - loss: 0.0238 - mse: 0.0238 - mae: 0.1154 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1155\n",
      "Epoch 18/1000\n",
      "32434/32478 [============================>.] - ETA: 0s - loss: 0.0237 - mse: 0.0237 - mae: 0.1152\n",
      "Epoch 18: saving model to saved_weights/saved-model-epoch-18-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 18: mse improved from 0.02378 to 0.02372, saving model to best_saved_model\n",
      "\n",
      "Epoch 18: mse improved from 0.02378 to 0.02372, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 629us/step - loss: 0.0237 - mse: 0.0237 - mae: 0.1152 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1153\n",
      "Epoch 19/1000\n",
      "32435/32478 [============================>.] - ETA: 0s - loss: 0.0237 - mse: 0.0237 - mae: 0.1151\n",
      "Epoch 19: saving model to saved_weights/saved-model-epoch-19-mse-0.02-mae-0.12.hdf5\n",
      "\n",
      "Epoch 19: mse improved from 0.02372 to 0.02365, saving model to best_saved_model\n",
      "\n",
      "Epoch 19: mse improved from 0.02372 to 0.02365, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 609us/step - loss: 0.0237 - mse: 0.0237 - mae: 0.1151 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1151\n",
      "Epoch 20/1000\n",
      "32427/32478 [============================>.] - ETA: 0s - loss: 0.0236 - mse: 0.0236 - mae: 0.1149\n",
      "Epoch 20: saving model to saved_weights/saved-model-epoch-20-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 20: mse improved from 0.02365 to 0.02359, saving model to best_saved_model\n",
      "\n",
      "Epoch 20: mse improved from 0.02365 to 0.02359, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 630us/step - loss: 0.0236 - mse: 0.0236 - mae: 0.1149 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1150\n",
      "Epoch 21/1000\n",
      "32402/32478 [============================>.] - ETA: 0s - loss: 0.0235 - mse: 0.0235 - mae: 0.1147\n",
      "Epoch 21: saving model to saved_weights/saved-model-epoch-21-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 21: mse improved from 0.02359 to 0.02353, saving model to best_saved_model\n",
      "\n",
      "Epoch 21: mse improved from 0.02359 to 0.02353, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 628us/step - loss: 0.0235 - mse: 0.0235 - mae: 0.1147 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1148\n",
      "Epoch 22/1000\n",
      "32444/32478 [============================>.] - ETA: 0s - loss: 0.0235 - mse: 0.0235 - mae: 0.1146\n",
      "Epoch 22: saving model to saved_weights/saved-model-epoch-22-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 22: mse improved from 0.02353 to 0.02347, saving model to best_saved_model\n",
      "\n",
      "Epoch 22: mse improved from 0.02353 to 0.02347, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 632us/step - loss: 0.0235 - mse: 0.0235 - mae: 0.1146 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1147\n",
      "Epoch 23/1000\n",
      "32397/32478 [============================>.] - ETA: 0s - loss: 0.0234 - mse: 0.0234 - mae: 0.1144\n",
      "Epoch 23: saving model to saved_weights/saved-model-epoch-23-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 23: mse improved from 0.02347 to 0.02341, saving model to best_saved_model\n",
      "\n",
      "Epoch 23: mse improved from 0.02347 to 0.02341, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 704us/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1144 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1145\n",
      "Epoch 24/1000\n",
      "32393/32478 [============================>.] - ETA: 0s - loss: 0.0234 - mse: 0.0234 - mae: 0.1143\n",
      "Epoch 24: saving model to saved_weights/saved-model-epoch-24-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 24: mse improved from 0.02341 to 0.02335, saving model to best_saved_model\n",
      "\n",
      "Epoch 24: mse improved from 0.02341 to 0.02335, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 622us/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1143 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1144\n",
      "Epoch 25/1000\n",
      "32408/32478 [============================>.] - ETA: 0s - loss: 0.0233 - mse: 0.0233 - mae: 0.1141\n",
      "Epoch 25: saving model to saved_weights/saved-model-epoch-25-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 25: mse improved from 0.02335 to 0.02329, saving model to best_saved_model\n",
      "\n",
      "Epoch 25: mse improved from 0.02335 to 0.02329, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 608us/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1141 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1142\n",
      "Epoch 26/1000\n",
      "32411/32478 [============================>.] - ETA: 0s - loss: 0.0232 - mse: 0.0232 - mae: 0.1139\n",
      "Epoch 26: saving model to saved_weights/saved-model-epoch-26-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 26: mse improved from 0.02329 to 0.02322, saving model to best_saved_model\n",
      "\n",
      "Epoch 26: mse improved from 0.02329 to 0.02322, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 603us/step - loss: 0.0232 - mse: 0.0232 - mae: 0.1139 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1140\n",
      "Epoch 27/1000\n",
      "32438/32478 [============================>.] - ETA: 0s - loss: 0.0231 - mse: 0.0231 - mae: 0.1138\n",
      "Epoch 27: saving model to saved_weights/saved-model-epoch-27-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 27: mse improved from 0.02322 to 0.02315, saving model to best_saved_model\n",
      "\n",
      "Epoch 27: mse improved from 0.02322 to 0.02315, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 606us/step - loss: 0.0231 - mse: 0.0231 - mae: 0.1138 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1139\n",
      "Epoch 28/1000\n",
      "32447/32478 [============================>.] - ETA: 0s - loss: 0.0231 - mse: 0.0231 - mae: 0.1136\n",
      "Epoch 28: saving model to saved_weights/saved-model-epoch-28-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 28: mse improved from 0.02315 to 0.02307, saving model to best_saved_model\n",
      "\n",
      "Epoch 28: mse improved from 0.02315 to 0.02307, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 622us/step - loss: 0.0231 - mse: 0.0231 - mae: 0.1136 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1137\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32438/32478 [============================>.] - ETA: 0s - loss: 0.0230 - mse: 0.0230 - mae: 0.1134\n",
      "Epoch 29: saving model to saved_weights/saved-model-epoch-29-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 29: mse improved from 0.02307 to 0.02300, saving model to best_saved_model\n",
      "\n",
      "Epoch 29: mse improved from 0.02307 to 0.02300, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 20s 619us/step - loss: 0.0230 - mse: 0.0230 - mae: 0.1134 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1135\n",
      "Epoch 30/1000\n",
      "32406/32478 [============================>.] - ETA: 0s - loss: 0.0229 - mse: 0.0229 - mae: 0.1132\n",
      "Epoch 30: saving model to saved_weights/saved-model-epoch-30-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 30: mse improved from 0.02300 to 0.02293, saving model to best_saved_model\n",
      "\n",
      "Epoch 30: mse improved from 0.02300 to 0.02293, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 784us/step - loss: 0.0229 - mse: 0.0229 - mae: 0.1132 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1134\n",
      "Epoch 31/1000\n",
      "32438/32478 [============================>.] - ETA: 0s - loss: 0.0229 - mse: 0.0229 - mae: 0.1131\n",
      "Epoch 31: saving model to saved_weights/saved-model-epoch-31-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 31: mse improved from 0.02293 to 0.02286, saving model to best_saved_model\n",
      "\n",
      "Epoch 31: mse improved from 0.02293 to 0.02286, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 28s 868us/step - loss: 0.0229 - mse: 0.0229 - mae: 0.1131 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1132\n",
      "Epoch 32/1000\n",
      "32406/32478 [============================>.] - ETA: 0s - loss: 0.0228 - mse: 0.0228 - mae: 0.1130\n",
      "Epoch 32: saving model to saved_weights/saved-model-epoch-32-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 32: mse improved from 0.02286 to 0.02281, saving model to best_saved_model\n",
      "\n",
      "Epoch 32: mse improved from 0.02286 to 0.02281, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 37s 1ms/step - loss: 0.0228 - mse: 0.0228 - mae: 0.1130 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1131\n",
      "Epoch 33/1000\n",
      "32442/32478 [============================>.] - ETA: 0s - loss: 0.0228 - mse: 0.0228 - mae: 0.1128\n",
      "Epoch 33: saving model to saved_weights/saved-model-epoch-33-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 33: mse improved from 0.02281 to 0.02276, saving model to best_saved_model\n",
      "\n",
      "Epoch 33: mse improved from 0.02281 to 0.02276, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 29s 905us/step - loss: 0.0228 - mse: 0.0228 - mae: 0.1128 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1130\n",
      "Epoch 34/1000\n",
      "32473/32478 [============================>.] - ETA: 0s - loss: 0.0227 - mse: 0.0227 - mae: 0.1127\n",
      "Epoch 34: saving model to saved_weights/saved-model-epoch-34-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 34: mse improved from 0.02276 to 0.02271, saving model to best_saved_model\n",
      "\n",
      "Epoch 34: mse improved from 0.02276 to 0.02271, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 765us/step - loss: 0.0227 - mse: 0.0227 - mae: 0.1127 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1129\n",
      "Epoch 35/1000\n",
      "32410/32478 [============================>.] - ETA: 0s - loss: 0.0227 - mse: 0.0227 - mae: 0.1126\n",
      "Epoch 35: saving model to saved_weights/saved-model-epoch-35-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 35: mse improved from 0.02271 to 0.02267, saving model to best_saved_model\n",
      "\n",
      "Epoch 35: mse improved from 0.02271 to 0.02267, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 710us/step - loss: 0.0227 - mse: 0.0227 - mae: 0.1126 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1128\n",
      "Epoch 36/1000\n",
      "32478/32478 [==============================] - ETA: 0s - loss: 0.0226 - mse: 0.0226 - mae: 0.1126\n",
      "Epoch 36: saving model to saved_weights/saved-model-epoch-36-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 36: mse improved from 0.02267 to 0.02264, saving model to best_saved_model\n",
      "\n",
      "Epoch 36: mse improved from 0.02267 to 0.02264, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 706us/step - loss: 0.0226 - mse: 0.0226 - mae: 0.1126 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1127\n",
      "Epoch 37/1000\n",
      "32455/32478 [============================>.] - ETA: 0s - loss: 0.0226 - mse: 0.0226 - mae: 0.1125\n",
      "Epoch 37: saving model to saved_weights/saved-model-epoch-37-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 37: mse improved from 0.02264 to 0.02260, saving model to best_saved_model\n",
      "\n",
      "Epoch 37: mse improved from 0.02264 to 0.02260, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 667us/step - loss: 0.0226 - mse: 0.0226 - mae: 0.1125 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1126\n",
      "Epoch 38/1000\n",
      "32474/32478 [============================>.] - ETA: 0s - loss: 0.0226 - mse: 0.0226 - mae: 0.1124\n",
      "Epoch 38: saving model to saved_weights/saved-model-epoch-38-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 38: mse improved from 0.02260 to 0.02256, saving model to best_saved_model\n",
      "\n",
      "Epoch 38: mse improved from 0.02260 to 0.02256, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 37s 1ms/step - loss: 0.0226 - mse: 0.0226 - mae: 0.1124 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1125\n",
      "Epoch 39/1000\n",
      "32441/32478 [============================>.] - ETA: 0s - loss: 0.0225 - mse: 0.0225 - mae: 0.1123\n",
      "Epoch 39: saving model to saved_weights/saved-model-epoch-39-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 39: mse improved from 0.02256 to 0.02253, saving model to best_saved_model\n",
      "\n",
      "Epoch 39: mse improved from 0.02256 to 0.02253, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 33s 1ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1123 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1124\n",
      "Epoch 40/1000\n",
      "32462/32478 [============================>.] - ETA: 0s - loss: 0.0225 - mse: 0.0225 - mae: 0.1122\n",
      "Epoch 40: saving model to saved_weights/saved-model-epoch-40-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 40: mse improved from 0.02253 to 0.02249, saving model to best_saved_model\n",
      "\n",
      "Epoch 40: mse improved from 0.02253 to 0.02249, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 814us/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1122 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1123\n",
      "Epoch 41/1000\n",
      "32467/32478 [============================>.] - ETA: 0s - loss: 0.0225 - mse: 0.0225 - mae: 0.1121\n",
      "Epoch 41: saving model to saved_weights/saved-model-epoch-41-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 41: mse improved from 0.02249 to 0.02245, saving model to best_saved_model\n",
      "\n",
      "Epoch 41: mse improved from 0.02249 to 0.02245, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 27s 834us/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1121 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1122\n",
      "Epoch 42/1000\n",
      "32449/32478 [============================>.] - ETA: 0s - loss: 0.0224 - mse: 0.0224 - mae: 0.1120\n",
      "Epoch 42: saving model to saved_weights/saved-model-epoch-42-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 42: mse improved from 0.02245 to 0.02241, saving model to best_saved_model\n",
      "\n",
      "Epoch 42: mse improved from 0.02245 to 0.02241, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 35s 1ms/step - loss: 0.0224 - mse: 0.0224 - mae: 0.1120 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1121\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32478 [============================>.] - ETA: 0s - loss: 0.0224 - mse: 0.0224 - mae: 0.1119\n",
      "Epoch 43: saving model to saved_weights/saved-model-epoch-43-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 43: mse improved from 0.02241 to 0.02238, saving model to best_saved_model\n",
      "\n",
      "Epoch 43: mse improved from 0.02241 to 0.02238, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 32s 992us/step - loss: 0.0224 - mse: 0.0224 - mae: 0.1119 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1120\n",
      "Epoch 44/1000\n",
      "32470/32478 [============================>.] - ETA: 0s - loss: 0.0223 - mse: 0.0223 - mae: 0.1118\n",
      "Epoch 44: saving model to saved_weights/saved-model-epoch-44-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 44: mse improved from 0.02238 to 0.02234, saving model to best_saved_model\n",
      "\n",
      "Epoch 44: mse improved from 0.02238 to 0.02234, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 694us/step - loss: 0.0223 - mse: 0.0223 - mae: 0.1118 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1119\n",
      "Epoch 45/1000\n",
      "32470/32478 [============================>.] - ETA: 0s - loss: 0.0223 - mse: 0.0223 - mae: 0.1117\n",
      "Epoch 45: saving model to saved_weights/saved-model-epoch-45-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 45: mse improved from 0.02234 to 0.02230, saving model to best_saved_model\n",
      "\n",
      "Epoch 45: mse improved from 0.02234 to 0.02230, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 671us/step - loss: 0.0223 - mse: 0.0223 - mae: 0.1117 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1118\n",
      "Epoch 46/1000\n",
      "32429/32478 [============================>.] - ETA: 0s - loss: 0.0223 - mse: 0.0223 - mae: 0.1116\n",
      "Epoch 46: saving model to saved_weights/saved-model-epoch-46-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 46: mse improved from 0.02230 to 0.02227, saving model to best_saved_model\n",
      "\n",
      "Epoch 46: mse improved from 0.02230 to 0.02227, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 809us/step - loss: 0.0223 - mse: 0.0223 - mae: 0.1116 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1117\n",
      "Epoch 47/1000\n",
      "32458/32478 [============================>.] - ETA: 0s - loss: 0.0222 - mse: 0.0222 - mae: 0.1115\n",
      "Epoch 47: saving model to saved_weights/saved-model-epoch-47-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 47: mse improved from 0.02227 to 0.02224, saving model to best_saved_model\n",
      "\n",
      "Epoch 47: mse improved from 0.02227 to 0.02224, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 32s 990us/step - loss: 0.0222 - mse: 0.0222 - mae: 0.1115 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1116\n",
      "Epoch 48/1000\n",
      "32459/32478 [============================>.] - ETA: 0s - loss: 0.0222 - mse: 0.0222 - mae: 0.1114\n",
      "Epoch 48: saving model to saved_weights/saved-model-epoch-48-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 48: mse improved from 0.02224 to 0.02221, saving model to best_saved_model\n",
      "\n",
      "Epoch 48: mse improved from 0.02224 to 0.02221, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 34s 1ms/step - loss: 0.0222 - mse: 0.0222 - mae: 0.1114 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1116\n",
      "Epoch 49/1000\n",
      "32465/32478 [============================>.] - ETA: 0s - loss: 0.0222 - mse: 0.0222 - mae: 0.1114\n",
      "Epoch 49: saving model to saved_weights/saved-model-epoch-49-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 49: mse improved from 0.02221 to 0.02219, saving model to best_saved_model\n",
      "\n",
      "Epoch 49: mse improved from 0.02221 to 0.02219, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 33s 1ms/step - loss: 0.0222 - mse: 0.0222 - mae: 0.1114 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1115\n",
      "Epoch 50/1000\n",
      "32439/32478 [============================>.] - ETA: 0s - loss: 0.0222 - mse: 0.0222 - mae: 0.1113\n",
      "Epoch 50: saving model to saved_weights/saved-model-epoch-50-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 50: mse improved from 0.02219 to 0.02217, saving model to best_saved_model\n",
      "\n",
      "Epoch 50: mse improved from 0.02219 to 0.02217, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 34s 1ms/step - loss: 0.0222 - mse: 0.0222 - mae: 0.1113 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1114\n",
      "Epoch 51/1000\n",
      "32472/32478 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1112\n",
      "Epoch 51: saving model to saved_weights/saved-model-epoch-51-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 51: mse improved from 0.02217 to 0.02215, saving model to best_saved_model\n",
      "\n",
      "Epoch 51: mse improved from 0.02217 to 0.02215, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 807us/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1112 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1114\n",
      "Epoch 52/1000\n",
      "32455/32478 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1112\n",
      "Epoch 52: saving model to saved_weights/saved-model-epoch-52-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 52: mse improved from 0.02215 to 0.02213, saving model to best_saved_model\n",
      "\n",
      "Epoch 52: mse improved from 0.02215 to 0.02213, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 781us/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1112 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1113\n",
      "Epoch 53/1000\n",
      "32442/32478 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1111\n",
      "Epoch 53: saving model to saved_weights/saved-model-epoch-53-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 53: mse improved from 0.02213 to 0.02211, saving model to best_saved_model\n",
      "\n",
      "Epoch 53: mse improved from 0.02213 to 0.02211, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 787us/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1111 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1113\n",
      "Epoch 54/1000\n",
      "32440/32478 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1111\n",
      "Epoch 54: saving model to saved_weights/saved-model-epoch-54-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 54: mse improved from 0.02211 to 0.02209, saving model to best_saved_model\n",
      "\n",
      "Epoch 54: mse improved from 0.02211 to 0.02209, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 714us/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1111 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1112\n",
      "Epoch 55/1000\n",
      "32455/32478 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1110\n",
      "Epoch 55: saving model to saved_weights/saved-model-epoch-55-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 55: mse improved from 0.02209 to 0.02208, saving model to best_saved_model\n",
      "\n",
      "Epoch 55: mse improved from 0.02209 to 0.02208, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 664us/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1110 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1112\n",
      "Epoch 56/1000\n",
      "32397/32478 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1110\n",
      "Epoch 56: saving model to saved_weights/saved-model-epoch-56-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 56: mse improved from 0.02208 to 0.02206, saving model to best_saved_model\n",
      "\n",
      "Epoch 56: mse improved from 0.02208 to 0.02206, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 670us/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1110 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1111\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32430/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1110\n",
      "Epoch 57: saving model to saved_weights/saved-model-epoch-57-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 57: mse improved from 0.02206 to 0.02205, saving model to best_saved_model\n",
      "\n",
      "Epoch 57: mse improved from 0.02206 to 0.02205, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 632us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1110 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1111\n",
      "Epoch 58/1000\n",
      "32446/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1109\n",
      "Epoch 58: saving model to saved_weights/saved-model-epoch-58-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 58: mse improved from 0.02205 to 0.02203, saving model to best_saved_model\n",
      "\n",
      "Epoch 58: mse improved from 0.02205 to 0.02203, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 651us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1109 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1110\n",
      "Epoch 59/1000\n",
      "32420/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1109\n",
      "Epoch 59: saving model to saved_weights/saved-model-epoch-59-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 59: mse improved from 0.02203 to 0.02202, saving model to best_saved_model\n",
      "\n",
      "Epoch 59: mse improved from 0.02203 to 0.02202, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 700us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1109 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1110\n",
      "Epoch 60/1000\n",
      "32444/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1108\n",
      "Epoch 60: saving model to saved_weights/saved-model-epoch-60-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 60: mse improved from 0.02202 to 0.02201, saving model to best_saved_model\n",
      "\n",
      "Epoch 60: mse improved from 0.02202 to 0.02201, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 684us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1108 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1110\n",
      "Epoch 61/1000\n",
      "32430/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1108\n",
      "Epoch 61: saving model to saved_weights/saved-model-epoch-61-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 61: mse improved from 0.02201 to 0.02199, saving model to best_saved_model\n",
      "\n",
      "Epoch 61: mse improved from 0.02201 to 0.02199, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 21s 644us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1108 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1109\n",
      "Epoch 62/1000\n",
      "32446/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1107\n",
      "Epoch 62: saving model to saved_weights/saved-model-epoch-62-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 62: mse improved from 0.02199 to 0.02198, saving model to best_saved_model\n",
      "\n",
      "Epoch 62: mse improved from 0.02199 to 0.02198, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 746us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1107 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1109\n",
      "Epoch 63/1000\n",
      "32462/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1107\n",
      "Epoch 63: saving model to saved_weights/saved-model-epoch-63-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 63: mse improved from 0.02198 to 0.02197, saving model to best_saved_model\n",
      "\n",
      "Epoch 63: mse improved from 0.02198 to 0.02197, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 694us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1107 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1108\n",
      "Epoch 64/1000\n",
      "32444/32478 [============================>.] - ETA: 0s - loss: 0.0220 - mse: 0.0220 - mae: 0.1107\n",
      "Epoch 64: saving model to saved_weights/saved-model-epoch-64-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 64: mse improved from 0.02197 to 0.02195, saving model to best_saved_model\n",
      "\n",
      "Epoch 64: mse improved from 0.02197 to 0.02195, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 28s 854us/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1107 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1108\n",
      "Epoch 65/1000\n",
      "32457/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1106\n",
      "Epoch 65: saving model to saved_weights/saved-model-epoch-65-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 65: mse improved from 0.02195 to 0.02194, saving model to best_saved_model\n",
      "\n",
      "Epoch 65: mse improved from 0.02195 to 0.02194, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 38s 1ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1106 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1108\n",
      "Epoch 66/1000\n",
      "32440/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1106\n",
      "Epoch 66: saving model to saved_weights/saved-model-epoch-66-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 66: mse improved from 0.02194 to 0.02193, saving model to best_saved_model\n",
      "\n",
      "Epoch 66: mse improved from 0.02194 to 0.02193, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 39s 1ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1106 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1107\n",
      "Epoch 67/1000\n",
      "32449/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1106\n",
      "Epoch 67: saving model to saved_weights/saved-model-epoch-67-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 67: mse improved from 0.02193 to 0.02192, saving model to best_saved_model\n",
      "\n",
      "Epoch 67: mse improved from 0.02193 to 0.02192, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 31s 954us/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1106 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1107\n",
      "Epoch 68/1000\n",
      "32432/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1105\n",
      "Epoch 68: saving model to saved_weights/saved-model-epoch-68-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 68: mse improved from 0.02192 to 0.02191, saving model to best_saved_model\n",
      "\n",
      "Epoch 68: mse improved from 0.02192 to 0.02191, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 761us/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1105 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1107\n",
      "Epoch 69/1000\n",
      "32464/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1105\n",
      "Epoch 69: saving model to saved_weights/saved-model-epoch-69-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 69: mse improved from 0.02191 to 0.02190, saving model to best_saved_model\n",
      "\n",
      "Epoch 69: mse improved from 0.02191 to 0.02190, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 33s 1ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1105 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1106\n",
      "Epoch 70/1000\n",
      "32404/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1105\n",
      "Epoch 70: saving model to saved_weights/saved-model-epoch-70-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 70: mse improved from 0.02190 to 0.02189, saving model to best_saved_model\n",
      "\n",
      "Epoch 70: mse improved from 0.02190 to 0.02189, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 802us/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1105 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1106\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32442/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1104\n",
      "Epoch 71: saving model to saved_weights/saved-model-epoch-71-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 71: mse improved from 0.02189 to 0.02188, saving model to best_saved_model\n",
      "\n",
      "Epoch 71: mse improved from 0.02189 to 0.02188, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 677us/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1104 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1106\n",
      "Epoch 72/1000\n",
      "32465/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1104\n",
      "Epoch 72: saving model to saved_weights/saved-model-epoch-72-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 72: mse improved from 0.02188 to 0.02187, saving model to best_saved_model\n",
      "\n",
      "Epoch 72: mse improved from 0.02188 to 0.02187, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 784us/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1104 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1106\n",
      "Epoch 73/1000\n",
      "32474/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1104\n",
      "Epoch 73: saving model to saved_weights/saved-model-epoch-73-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 73: mse improved from 0.02187 to 0.02186, saving model to best_saved_model\n",
      "\n",
      "Epoch 73: mse improved from 0.02187 to 0.02186, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 738us/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1104 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1105\n",
      "Epoch 74/1000\n",
      "32458/32478 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219 - mae: 0.1104\n",
      "Epoch 74: saving model to saved_weights/saved-model-epoch-74-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 74: mse improved from 0.02186 to 0.02185, saving model to best_saved_model\n",
      "\n",
      "Epoch 74: mse improved from 0.02186 to 0.02185, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 807us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1104 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1105\n",
      "Epoch 75/1000\n",
      "32425/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1103\n",
      "Epoch 75: saving model to saved_weights/saved-model-epoch-75-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 75: mse improved from 0.02185 to 0.02184, saving model to best_saved_model\n",
      "\n",
      "Epoch 75: mse improved from 0.02185 to 0.02184, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 680us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1103 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1105\n",
      "Epoch 76/1000\n",
      "32415/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1103\n",
      "Epoch 76: saving model to saved_weights/saved-model-epoch-76-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 76: mse improved from 0.02184 to 0.02183, saving model to best_saved_model\n",
      "\n",
      "Epoch 76: mse improved from 0.02184 to 0.02183, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 689us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1103 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1105\n",
      "Epoch 77/1000\n",
      "32473/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1103\n",
      "Epoch 77: saving model to saved_weights/saved-model-epoch-77-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 77: mse improved from 0.02183 to 0.02182, saving model to best_saved_model\n",
      "\n",
      "Epoch 77: mse improved from 0.02183 to 0.02182, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 768us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1103 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1104\n",
      "Epoch 78/1000\n",
      "32441/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1103\n",
      "Epoch 78: saving model to saved_weights/saved-model-epoch-78-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 78: mse improved from 0.02182 to 0.02182, saving model to best_saved_model\n",
      "\n",
      "Epoch 78: mse improved from 0.02182 to 0.02182, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 728us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1103 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1104\n",
      "Epoch 79/1000\n",
      "32429/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1102\n",
      "Epoch 79: saving model to saved_weights/saved-model-epoch-79-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 79: mse improved from 0.02182 to 0.02181, saving model to best_saved_model\n",
      "\n",
      "Epoch 79: mse improved from 0.02182 to 0.02181, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 719us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1102 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1104\n",
      "Epoch 80/1000\n",
      "32450/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1102\n",
      "Epoch 80: saving model to saved_weights/saved-model-epoch-80-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 80: mse improved from 0.02181 to 0.02180, saving model to best_saved_model\n",
      "\n",
      "Epoch 80: mse improved from 0.02181 to 0.02180, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 733us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1102 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1104\n",
      "Epoch 81/1000\n",
      "32434/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1102\n",
      "Epoch 81: saving model to saved_weights/saved-model-epoch-81-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 81: mse improved from 0.02180 to 0.02180, saving model to best_saved_model\n",
      "\n",
      "Epoch 81: mse improved from 0.02180 to 0.02180, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 709us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1102 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1103\n",
      "Epoch 82/1000\n",
      "32451/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1102\n",
      "Epoch 82: saving model to saved_weights/saved-model-epoch-82-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 82: mse improved from 0.02180 to 0.02179, saving model to best_saved_model\n",
      "\n",
      "Epoch 82: mse improved from 0.02180 to 0.02179, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 702us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1102 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1103\n",
      "Epoch 83/1000\n",
      "32444/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1101\n",
      "Epoch 83: saving model to saved_weights/saved-model-epoch-83-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 83: mse improved from 0.02179 to 0.02178, saving model to best_saved_model\n",
      "\n",
      "Epoch 83: mse improved from 0.02179 to 0.02178, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 760us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1102 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1103\n",
      "Epoch 84/1000\n",
      "32478/32478 [==============================] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1101\n",
      "Epoch 84: saving model to saved_weights/saved-model-epoch-84-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 84: mse improved from 0.02178 to 0.02177, saving model to best_saved_model\n",
      "\n",
      "Epoch 84: mse improved from 0.02178 to 0.02177, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 729us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1101 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1103\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32436/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1101\n",
      "Epoch 85: saving model to saved_weights/saved-model-epoch-85-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 85: mse improved from 0.02177 to 0.02177, saving model to best_saved_model\n",
      "\n",
      "Epoch 85: mse improved from 0.02177 to 0.02177, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 731us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1101 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1103\n",
      "Epoch 86/1000\n",
      "32433/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1101\n",
      "Epoch 86: saving model to saved_weights/saved-model-epoch-86-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 86: mse improved from 0.02177 to 0.02176, saving model to best_saved_model\n",
      "\n",
      "Epoch 86: mse improved from 0.02177 to 0.02176, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 26s 793us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1101 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1102\n",
      "Epoch 87/1000\n",
      "32455/32478 [============================>.] - ETA: 0s - loss: 0.0218 - mse: 0.0218 - mae: 0.1101\n",
      "Epoch 87: saving model to saved_weights/saved-model-epoch-87-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 87: mse improved from 0.02176 to 0.02175, saving model to best_saved_model\n",
      "\n",
      "Epoch 87: mse improved from 0.02176 to 0.02175, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 24s 754us/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1101 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1102\n",
      "Epoch 88/1000\n",
      "32470/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1100\n",
      "Epoch 88: saving model to saved_weights/saved-model-epoch-88-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 88: mse improved from 0.02175 to 0.02175, saving model to best_saved_model\n",
      "\n",
      "Epoch 88: mse improved from 0.02175 to 0.02175, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 663us/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1100 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1102\n",
      "Epoch 89/1000\n",
      "32443/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1100\n",
      "Epoch 89: saving model to saved_weights/saved-model-epoch-89-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 89: mse improved from 0.02175 to 0.02174, saving model to best_saved_model\n",
      "\n",
      "Epoch 89: mse improved from 0.02175 to 0.02174, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 672us/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1100 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1102\n",
      "Epoch 90/1000\n",
      "32430/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1100\n",
      "Epoch 90: saving model to saved_weights/saved-model-epoch-90-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 90: mse improved from 0.02174 to 0.02173, saving model to best_saved_model\n",
      "\n",
      "Epoch 90: mse improved from 0.02174 to 0.02173, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 34s 1ms/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1100 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1101\n",
      "Epoch 91/1000\n",
      "32414/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1100\n",
      "Epoch 91: saving model to saved_weights/saved-model-epoch-91-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 91: mse improved from 0.02173 to 0.02173, saving model to best_saved_model\n",
      "\n",
      "Epoch 91: mse improved from 0.02173 to 0.02173, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 22s 664us/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1100 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1101\n",
      "Epoch 92/1000\n",
      "32470/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1100\n",
      "Epoch 92: saving model to saved_weights/saved-model-epoch-92-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 92: mse improved from 0.02173 to 0.02172, saving model to best_saved_model\n",
      "\n",
      "Epoch 92: mse improved from 0.02173 to 0.02172, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 28s 858us/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1100 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1101\n",
      "Epoch 93/1000\n",
      "32452/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1099\n",
      "Epoch 93: saving model to saved_weights/saved-model-epoch-93-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 93: mse improved from 0.02172 to 0.02172, saving model to best_saved_model\n",
      "\n",
      "Epoch 93: mse improved from 0.02172 to 0.02172, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 23s 719us/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1099 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1101\n",
      "Epoch 94/1000\n",
      "32472/32478 [============================>.] - ETA: 0s - loss: 0.0217 - mse: 0.0217 - mae: 0.1099\n",
      "Epoch 94: saving model to saved_weights/saved-model-epoch-94-mse-0.02-mae-0.11.hdf5\n",
      "\n",
      "Epoch 94: mse improved from 0.02172 to 0.02171, saving model to best_saved_model\n",
      "\n",
      "Epoch 94: mse improved from 0.02172 to 0.02171, saving model to best_saved_model\n",
      "INFO:tensorflow:Assets written to: best_saved_model/assets\n",
      "32478/32478 [==============================] - 25s 759us/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1099 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1101\n",
      "Epoch 95/1000\n",
      "27776/32478 [========================>.....] - ETA: 3s - loss: 0.0217 - mse: 0.0217 - mae: 0.1099"
     ]
    }
   ],
   "source": [
    "# train the model using SGD\n",
    "print(\"[INFO] training network...\")\n",
    "sgd = SGD(0.01)\n",
    "model.compile(loss=\"mse\", optimizer=sgd, metrics=['mse', 'mae', 'r_square'])\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=32, epochs=1000, \n",
    "              callbacks=[checkpoint_all, checkpoint_best, checkpoint_best_full],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91db9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e79ff7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "1710/1710 [==============================] - 1s 401us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.06      0.12     36783\n",
      "           1       0.05      0.19      0.08      1505\n",
      "           2       0.01      0.03      0.02       698\n",
      "           3       0.09      0.01      0.01      4413\n",
      "           4       0.01      0.00      0.01       962\n",
      "           5       0.01      0.03      0.02       985\n",
      "           6       0.09      0.47      0.15      2652\n",
      "           7       0.04      0.06      0.05      1930\n",
      "           8       0.00      0.01      0.00       237\n",
      "           9       0.13      0.38      0.19      3717\n",
      "          10       0.01      0.00      0.01       817\n",
      "          11       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10     54699\n",
      "   macro avg       0.10      0.10      0.05     54699\n",
      "weighted avg       0.51      0.10      0.11     54699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/altynbekaidarbekov/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/altynbekaidarbekov/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/altynbekaidarbekov/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34f2cc1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m), H\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m), H\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/anaconda3/envs/robotics_project/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
